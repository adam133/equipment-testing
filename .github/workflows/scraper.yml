name: Equipment Scraper

on:
  # Run weekly on Sundays at 2 AM UTC
  schedule:
    - cron: '0 2 * * 0'
  # Allow manual triggering
  workflow_dispatch:
    inputs:
      spider_name:
        description: 'Spider to run (leave empty for all)'
        required: false
        default: ''

# Required for OIDC authentication with AWS
permissions:
  id-token: write
  contents: read

jobs:
  scrape:
    name: Run Equipment Scrapers
    runs-on: ubuntu-latest
    environment: production
    permissions:
      id-token: write
      contents: read

    steps:
    - uses: actions/checkout@v4

    - name: Configure AWS credentials using OIDC
      uses: aws-actions/configure-aws-credentials@v4
      with:
        role-to-assume: ${{ secrets.AWS_DEPLOYMENT_ROLE_ARN }}
        aws-region: ${{ secrets.AWS_REGION }}
        role-session-name: GitHubActions-OpenAgDB-Scraper

    - name: Install uv
      uses: astral-sh/setup-uv@v3
      with:
        version: "latest"

    - name: Set up Python
      run: uv python install 3.12

    - name: Install dependencies
      run: |
        uv sync --all-extras

    - name: Run scrapers
      env:
        # S3 bucket for data storage
        S3_DATALAKE_BUCKET: ${{ secrets.S3_DATALAKE_BUCKET }}
        S3_ARTIFACTS_BUCKET: ${{ secrets.S3_ARTIFACTS_BUCKET }}
        AWS_REGION: ${{ secrets.AWS_REGION }}
      run: |
        if [ -z "${{ github.event.inputs.spider_name }}" ]; then
          echo "Running all spiders..."
          # Run all spiders (placeholder - would iterate through actual spiders)
          # uv run scrapy crawl tractordata
        else
          echo "Running spider: ${{ github.event.inputs.spider_name }}"
          # uv run scrapy crawl ${{ github.event.inputs.spider_name }}
        fi

    - name: Upload scraper logs
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: scraper-logs
        path: |
          *.log
          scrapy_*.json
        retention-days: 7
